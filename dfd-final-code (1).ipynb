{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6945939,"sourceType":"datasetVersion","datasetId":3989137}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import necessary libraries\nimport os\nimport numpy as np\nimport cv2\nfrom tensorflow.keras import layers, models\nfrom sklearn.model_selection import train_test_split","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport cv2\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport pickle\nfrom tensorflow.keras import layers, models\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define paths\ndataset_path = '/kaggle/input/1000-videos-split/1000_videos'#change the data set path\ntrain_path = os.path.join(dataset_path, 'train')\ntest_path = os.path.join(dataset_path, 'test')\nvalidation_path = os.path.join(dataset_path, 'validation')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define image size and channels\nImage_Size = 180  # Update this as necessary\nChannels = 3\nEpochs = 100 # Update this as necessary","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a function to load and preprocess images\ndef load_images(image_path, label):\n    images = []\n    labels = []\n    for img in os.listdir(image_path):\n        img_path = os.path.join(image_path, img)\n        img_data = cv2.imread(img_path)\n        img_data = cv2.resize(img_data, (Image_Size, Image_Size))\n        images.append(img_data)\n        labels.append(label)\n    return np.array(images), np.array(labels)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load training data\ntrain_real_images, train_real_labels = load_images('/kaggle/input/1000-videos-split/1000_videos/train/real', 0) #change the path\ntrain_fake_images, train_fake_labels = load_images('/kaggle/input/1000-videos-split/1000_videos/train/fake', 1) #change the path\n\n# Load validation data \nvalidation_real_images, validation_real_labels = load_images('/kaggle/input/1000-videos-split/1000_videos/validation/real', 0) #change the path\nvalidation_fake_images, validation_fake_labels = load_images('/kaggle/input/1000-videos-split/1000_videos/validation/fake', 1) #change the path\n\n# Load test data  # Load the test data here\ntest_real_images, test_real_labels = load_images('/kaggle/input/1000-videos-split/1000_videos/test/real', 0)  #change the path\ntest_fake_images, test_fake_labels = load_images('/kaggle/input/1000-videos-split/1000_videos/test/fake', 1) #change the path\n\n# Combine real and fake datasets\nx_train = np.concatenate((train_real_images, train_fake_images), axis=0)\ny_train = np.concatenate((train_real_labels, train_fake_labels), axis=0)\n\nx_validation = np.concatenate((validation_real_images, validation_fake_images), axis=0)\ny_validation = np.concatenate((validation_real_labels, validation_fake_labels), axis=0)\n\nx_test = np.concatenate((test_real_images, test_fake_images), axis=0) \ny_test = np.concatenate((test_real_labels, test_fake_labels), axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Normalize the images\nx_train = x_train / 255.0\nx_validation = x_validation / 255.0\nx_test = x_test / 255.0\n\nprint(f'Training data shape: {x_train.shape}, Labels shape: {y_train.shape}')\nprint(f'Validation data shape: {x_validation.shape}, Labels shape: {y_validation.shape}')\nprint(f'Test data shape: {x_test.shape}, Labels shape: {y_test.shape}')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build the model\nmodel = models.Sequential([\n    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(Image_Size, Image_Size, Channels)),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.Flatten(),\n    layers.Dense(64, activation='relu'),\n    layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\nhistory = model.fit(x_train, y_train, epochs=Epochs, validation_data=(x_validation, y_validation))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model\ntest_loss, test_acc = model.evaluate(x_test, y_test)\nprint(f'Test accuracy: {test_acc}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the prediction function for a video\ndef pred_video(model, video_path):\n    frames = []\n    img_data = cv2.imread(video_path)\n    img_data = cv2.resize(img_data, (Image_Size, Image_Size))\n    img_data = img_data / 255.0\n    frames.append(img_data)\n    frames = np.array(frames)\n    predictions = model.predict(frames)\n    final_prediction = np.mean(predictions)\n    return final_prediction, predictions\n# \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the prediction function for individual images\ndef pred(model, image):\n    image = tf.image.resize(image, [Image_Size, Image_Size])  # Resize to match the input shape\n    image = np.expand_dims(image, axis=0)  # Expand dims to match input shape\n    prediction = model.predict(image)\n    predicted_class = 'fake' if prediction[0] > 0.5 else 'real'\n    confidence = prediction[0][0] * 100 if predicted_class == 'fake' else (1 - prediction[0][0]) * 100\n    return predicted_class, confidence\n# ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the model\nimport pickle\nwith open('model_f_real_pickle_final', 'wb') as f:\n    pickle.dump(model, f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the saved model using pickle\nwith open('model_f_real_pickle_final', 'rb') as f:  # Update this path\n    model_saved = pickle.load(f)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming you have class names\nclass_names = ['fake', 'real']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# Function to load and preprocess an image from a given path\ndef load_and_preprocess_image(image_path):\n    image = tf.io.read_file(image_path)\n    image = tf.image.decode_image(image, channels=3)\n    image = tf.image.resize(image, [Image_Size, Image_Size])\n    image = image / 255.0  # Normalize to [0, 1]\n    return image\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Predict using the saved model\nplt.figure(figsize=(15, 15))\ntest_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)  # Create a dataset for testing\nfor images, labels in test_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        img = images[i].numpy().astype(\"uint8\")\n        img_display = img * 255.0  # Scale back to [0, 255] range\n        plt.imshow(img_display.astype(\"uint8\"))\n        predicted_class, confidence = pred(model_saved, images[i].numpy())\n        actual_class = class_names[labels[i]]\n        plt.title(f\"Actual: {actual_class},\\n Predicted: {predicted_class}.\\n Confidence: {confidence:.2f}%\")\n        plt.axis(\"off\")\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Add an image of your choice\nimage_path = '/kaggle/input/1000-videos-split/1000_videos/test/real/069_20.png' # Update this path\nimage = load_and_preprocess_image(image_path)\n# Plot and predict for the new image\nplt.figure(figsize=(6, 6))\nplt.imshow(image.numpy())\npredicted_class, confidence = pred(model_saved, image.numpy())\nplt.title(f\"Predicted: {predicted_class}\\nConfidence: {confidence:.2f}%\")\nplt.axis(\"off\")\nplt.show()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}